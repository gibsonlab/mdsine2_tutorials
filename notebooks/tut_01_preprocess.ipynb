{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kveXqCsHqISO"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gibsonlab/mdsine2_tutorials/blob/main/notebooks/tut_01_preprocess.ipynb)\n",
        "\n",
        "# Data wrangling\n",
        "Data organization and formatting is an important part of any workflow. For the current dataset (`./data/raw_tables/), we will:\n",
        "1. Remove a subject with incomplete data (a mouse jumped out of it's cage)\n",
        "2. Identify and seperate various experimental conditions\n",
        "    - Healthy subjects\n",
        "    - Unhealthy subjects\n",
        "    - Subjects with physical replicate qPCR data\n",
        "3. Make smaller \"toy\" datasets to use in the other tutorials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCizOMYdqISO",
        "outputId": "845ed5a4-85ec-412f-9f63-a3c5a20fd6c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  269k  100  269k    0     0   541k      0 --:--:-- --:--:-- --:--:--  541k\n",
            "Archive:  raw_tables.zip\n",
            "   creating: ./data/raw_tables/\n",
            "  inflating: ./data/raw_tables/perturbations.tsv  \n",
            "  inflating: ./data/raw_tables/qpcr.tsv  \n",
            "  inflating: ./data/raw_tables/metadata.tsv  \n",
            "  inflating: ./data/raw_tables/silva_species.tsv  \n",
            "  inflating: ./data/raw_tables/counts.tsv  \n",
            "  inflating: ./data/raw_tables/rdp_species.tsv  \n",
            "Cloning into 'MDSINE2'...\n",
            "remote: Enumerating objects: 3973, done.\u001b[K\n",
            "remote: Counting objects: 100% (904/904), done.\u001b[K\n",
            "remote: Compressing objects: 100% (258/258), done.\u001b[K\n",
            "remote: Total 3973 (delta 659), reused 887 (delta 646), pack-reused 3069\u001b[K\n",
            "Receiving objects: 100% (3973/3973), 78.22 MiB | 7.57 MiB/s, done.\n",
            "Resolving deltas: 100% (2645/2645), done.\n",
            "Branch 'cv-wip-mirror-dem' set up to track remote branch 'cv-wip-mirror-dem' from 'origin'.\n",
            "Switched to a new branch 'cv-wip-mirror-dem'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./MDSINE2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.8/dist-packages (from mdsine2==0.4.5) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from mdsine2==0.4.5) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from mdsine2==0.4.5) (1.7.3)\n",
            "Collecting matplotlib>=3.3.1\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from mdsine2==0.4.5) (0.11.2)\n",
            "Collecting h5py==2.9.0\n",
            "  Downloading h5py-2.9.0-cp38-cp38-manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.7.3\n",
            "  Downloading psutil-5.7.3.tar.gz (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx==2.3\n",
            "  Downloading networkx-2.3.zip (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numba==0.52\n",
            "  Downloading numba-0.52.0-cp38-cp38-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting biopython==1.78\n",
            "  Downloading biopython-1.78-cp38-cp38-manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting treeswift==1.1.14\n",
            "  Downloading treeswift-1.1.14-py2.py3-none-any.whl (32 kB)\n",
            "Collecting py2cytoscape==0.7.1\n",
            "  Downloading py2cytoscape-0.7.1.tar.gz (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mdsine2==0.4.5) (4.64.1)\n",
            "Collecting PyQt5\n",
            "  Downloading PyQt5-5.15.9-cp37-abi3-manylinux_2_17_x86_64.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ete3\n",
            "  Downloading ete3-3.1.2.tar.gz (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from h5py==2.9.0->mdsine2==0.4.5) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from networkx==2.3->mdsine2==0.4.5) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.52->mdsine2==0.4.5) (57.4.0)\n",
            "Collecting llvmlite<0.36,>=0.35.0\n",
            "  Downloading llvmlite-0.35.0-cp38-cp38-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.8/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (1.3.0)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.8/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (2.25.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from py2cytoscape==0.7.1->mdsine2==0.4.5) (3.0.9)\n",
            "Collecting python-igraph\n",
            "  Downloading python-igraph-0.10.4.tar.gz (9.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.1->mdsine2==0.4.5) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->mdsine2==0.4.5) (2022.7.1)\n",
            "Collecting PyQt5-Qt5>=5.15.2\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.11\n",
            "  Downloading PyQt5_sip-12.11.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (361 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.8/361.8 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting igraph==0.10.4\n",
            "  Downloading igraph-0.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->py2cytoscape==0.7.1->mdsine2==0.4.5) (2022.12.7)\n",
            "Building wheels for collected packages: mdsine2, networkx, psutil, py2cytoscape, ete3, sklearn, python-igraph\n",
            "  Building wheel for mdsine2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mdsine2: filename=mdsine2-0.4.5-cp38-cp38-linux_x86_64.whl size=347500 sha256=56331b1ff99f1e03227c770bedcfd781bada7a284a6198e66abf9a033fe04eb6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l96vcpur/wheels/65/97/60/8ebe4c65ed49112c078eed07ff85b0324d1512045c5c8fe993\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556009 sha256=cb5b47be349ecf0438fb40c32f97cddb358d569f4140bb3277a9af4d8e353ed6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/62/9e/0ed2d25fd4f5761e2d19568cda0c32716556dfa682e65ecf64\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.3-cp38-cp38-linux_x86_64.whl size=294861 sha256=00deee5ef595e5a54a424ecec764169eb75e3ac63c0215cf590f9523ea67de26\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/59/c2/38111ef4c354088a156bc95fbeb5396c0cac91a0f62f7158b9\n",
            "  Building wheel for py2cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py2cytoscape: filename=py2cytoscape-0.7.1-py3-none-any.whl size=78829 sha256=521680e67db30b947f866c4445265d8387a4182d81052b50b65a7693baff0402\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/c3/5b/76436ed5d5c54edcb37239175c9e978c7994ffc9f9b5f8472a\n",
            "  Building wheel for ete3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ete3: filename=ete3-3.1.2-py3-none-any.whl size=2273013 sha256=cd715bb6e42b809fd3ce59285af3f83af3270a5840560f455e5814b743c90fa6\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/96/a0/973292c4813e6b39b611bec535521655088425516959768f46\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=9a2256b7d7eb0e1d45fcd0932c5351ae384343d0ecb43a10052ac56dfd62737d\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for python-igraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-igraph: filename=python_igraph-0.10.4-py3-none-any.whl size=9076 sha256=b0a97264b9070fbb743c3c48e5effc7496f603989c5cd01020ea77a08faecb9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/eb/68/b70fc5f1163b5a3e9e6aaaea5fb57a8ff4c0c4988505a4fe0f\n",
            "Successfully built mdsine2 networkx psutil py2cytoscape ete3 sklearn python-igraph\n",
            "Installing collected packages: treeswift, texttable, sklearn, PyQt5-Qt5, ete3, PyQt5-sip, psutil, networkx, llvmlite, igraph, h5py, fonttools, contourpy, biopython, python-igraph, PyQt5, numba, matplotlib, py2cytoscape, mdsine2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "resampy 0.4.2 requires numba>=0.53, but you have numba 0.52.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyQt5-5.15.9 PyQt5-Qt5-5.15.2 PyQt5-sip-12.11.1 biopython-1.78 contourpy-1.0.7 ete3-3.1.2 fonttools-4.38.0 h5py-2.9.0 igraph-0.10.4 llvmlite-0.35.0 matplotlib-3.6.3 mdsine2-0.4.5 networkx-2.3 numba-0.52.0 psutil-5.7.3 py2cytoscape-0.7.1 python-igraph-0.10.4 sklearn-0.0.post1 texttable-1.6.7 treeswift-1.1.14\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !curl -LJO https://github.com/gibsonlab/mdsine2_tutorials/raw/main/data/raw_tables.zip\n",
        "    !mkdir -p ./data/ && unzip -o raw_tables.zip -d ./data/\n",
        "\n",
        "    !git clone https://github.com/gerberlab/MDSINE2\n",
        "    !pip install MDSINE2/.\n",
        "\n",
        "else:\n",
        "    !cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epmHpyo_qISP",
        "outputId": "f82b8e44-96ed-4a60-ae4f-df5c6078cdea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] Using default logger (stdout, stderr).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import mdsine2 as md2\n",
        "from mdsine2.util import make_toy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycjyTQoeqISP"
      },
      "outputs": [],
      "source": [
        "# Specify data input and output directories\n",
        "data_dir = Path('./data/')\n",
        "raw_data_dir = data_dir / 'raw_tables'\n",
        "healthy_data_dir = data_dir / 'healthy'\n",
        "replicates_data_dir = data_dir / 'replicates'\n",
        "\n",
        "for ff in [healthy_data_dir, replicates_data_dir]:\n",
        "    ff.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RMpcWKpqISP"
      },
      "outputs": [],
      "source": [
        "# Read the data files\n",
        "data = {}\n",
        "tsv_files = sorted(raw_data_dir.glob('*.tsv'))\n",
        "\n",
        "sep = '\\t'\n",
        "\n",
        "for tsv_f in tsv_files:\n",
        "    data[tsv_f.stem] = pd.read_csv(tsv_f, index_col=0, sep=sep)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_e3YyoyqISP"
      },
      "source": [
        " ### Task 1: Identify subjects that have no associated qpcr data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DQRrHGFqISQ"
      },
      "outputs": [],
      "source": [
        "subj_counts = set(data['counts'].columns.to_list())\n",
        "subj_qpcr = set(data['qpcr'].index.to_list())\n",
        "\n",
        "subj_counts_only = list(subj_counts - subj_qpcr)\n",
        "\n",
        "data['counts'] = data['counts'].drop(columns=subj_counts_only)\n",
        "data['metadata'] = data['metadata'].drop(index=subj_counts_only)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvMoEAQ9qISR"
      },
      "source": [
        " ### Task 2: Identify replicate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6vwU8mpqISR"
      },
      "outputs": [],
      "source": [
        "# Create a function to extract data based on a given tag.\n",
        "\n",
        "def identify_subjects_by_tag(data, tags, exclude=False):\n",
        "    \"\"\" Filter out subjects by a tag.\n",
        "    \"\"\"\n",
        "    data = data.copy()\n",
        "    all_subj_ids = data['counts'].columns\n",
        "\n",
        "    filter_func = lambda x: any([x.startswith(t) for t in tags])\n",
        "    subj_ids = list(filter(filter_func, all_subj_ids))\n",
        "\n",
        "    if exclude:\n",
        "        subj_ids = sorted(set(data['counts'].columns) - set(subj_ids))\n",
        "    \n",
        "    data['counts'] = data['counts'][subj_ids]\n",
        "    data['metadata'] = data['metadata'].loc[subj_ids]\n",
        "    data['qpcr'] = data['qpcr'].loc[subj_ids]\n",
        "    return data\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU4JLg_uqISS"
      },
      "outputs": [],
      "source": [
        "# First identify replicates and save data\n",
        "rep_tag = \"M2-\"\n",
        "tags = [rep_tag]\n",
        "\n",
        "replicates = identify_subjects_by_tag(data, tags)\n",
        "\n",
        "# Write data to subjects directory\n",
        "for key in replicates.keys():\n",
        "    replicates[key].to_csv(\n",
        "        replicates_data_dir / (key + '.tsv'),\n",
        "        sep=sep, \n",
        "        index=True, \n",
        "        header=True,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwZEz3LsqISS"
      },
      "outputs": [],
      "source": [
        "# Then identify subject data only by excluding the replicate and inoculum data.\n",
        "healthy_tags = ['2-', '3-', '4-', '5-']\n",
        "\n",
        "healthy = identify_subjects_by_tag(data, healthy_tags)\n",
        "\n",
        "# Write data to subjects directory\n",
        "for key in healthy.keys():\n",
        "    healthy[key].to_csv(\n",
        "        healthy_data_dir / (key + '.tsv'),\n",
        "        sep=sep, \n",
        "        index=True, \n",
        "        header=True,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y040Hqs9qIST"
      },
      "source": [
        " ### Task 3: Make toy datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfnrCik-qIST",
        "outputId": "948b01e5-1447-493f-8fcd-2d132812bc86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] TaxaSet parsng new taxonomy table. Resetting\n",
            "[INFO] No `name` found - assuming index is the name\n",
            "[DEBUG] Reseting perturbations\n",
            "[INFO] TaxaSet parsng new taxonomy table. Resetting\n",
            "[INFO] No `name` found - assuming index is the name\n",
            "[DEBUG] Reseting perturbations\n",
            "[INFO] TaxaSet parsng new taxonomy table. Resetting\n",
            "[INFO] No `name` found - assuming index is the name\n",
            "[DEBUG] Reseting perturbations\n",
            "[INFO] TaxaSet parsng new taxonomy table. Resetting\n",
            "[INFO] No `name` found - assuming index is the name\n",
            "[DEBUG] Reseting perturbations\n"
          ]
        }
      ],
      "source": [
        "# Read in the preprocessed files, and make toy datasets.\n",
        "for ff in [healthy_data_dir, replicates_data_dir]:\n",
        "    tsv_files = sorted(ff.glob('*.tsv'))\n",
        "    tsv_files = {f.stem : f for f in tsv_files}\n",
        "\n",
        "    # Create a small toy dataset from full dataset\n",
        "    toy_study = make_toy(\n",
        "        metadata_f=tsv_files['metadata'],\n",
        "        qpcr_f=tsv_files['qpcr'],\n",
        "        reads_f=tsv_files['counts'],\n",
        "        taxa_f=tsv_files['rdp_species'],\n",
        "        perturbations_f=tsv_files['perturbations'],\n",
        "        n_taxa=15,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08W86zQarUBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mdsine2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "beba50113cf04c9ca1c9a3ac6af58136127bf597d62df57e30b29cd1f5120155"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}